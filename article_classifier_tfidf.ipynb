{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multi-class classification \n",
    "# Feature Extraction using tfidf\n",
    "# I have followed a nouns-only approach so that only nouns from the articles are used for forming tfidf vectors. \n",
    "# Nouns only approach tends to give better results as compared to standard tfidf\n",
    "# Performance of various classifiers have been compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import codecs\n",
    "\n",
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boycott', 'demonstrations', 'hunger_strike', 'lawsuit', 'non_protest1', 'riots']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>representative trondheim norway city good serv...</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bd committee thursday evening news un human ri...</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man israeli force thursday morning guard park ...</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khader adnan prisoner hunger striker release d...</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>israel eu plan settlement product eu member st...</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Doc    label\n",
       "0  representative trondheim norway city good serv...  boycott\n",
       "1  bd committee thursday evening news un human ri...  boycott\n",
       "2  man israeli force thursday morning guard park ...  boycott\n",
       "3  khader adnan prisoner hunger striker release d...  boycott\n",
       "4  israel eu plan settlement product eu member st...  boycott"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data preprocessing\n",
    "loc='C:/Users/Ruchita/Desktop/document classification/train_data'\n",
    "categories=listdir(loc)\n",
    "#categories=['protest_data','non_protest']\n",
    "categories.remove('non_protest')\n",
    "#categories.remove('README.TXT')\n",
    "print(categories)\n",
    "#print(categories)\n",
    "all_data=pd.DataFrame(columns=['Doc','label'])\n",
    "docs=[]\n",
    "labels=[]\n",
    "\n",
    "wnl=WordNetLemmatizer()\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "for ct in categories:\n",
    "    floc=loc+\"/\"+ct\n",
    "    j=listdir(floc)\n",
    "    for i in j:\n",
    "        file=codecs.open(floc+\"/\"+i,'r')\n",
    "        txt=file.read()\n",
    "            \n",
    "        try:\n",
    "            lst=txt.strip().split()\n",
    "    \n",
    "            newlst=lst[:lst.index('[â€¦]')]\n",
    "            s=' '\n",
    "            txt=s.join(newlst)\n",
    "                \n",
    "        except:\n",
    "            txt=txt\n",
    "        \n",
    "        # only include nouns from sentences for making tfidf vectors\n",
    "        lst2=[word for (word,tag) in pos_tag(txt.strip().split()) if re.match(r'NN',tag)!=None]\n",
    "        \n",
    "        s=' '\n",
    "        txt=s.join(lst2)\n",
    "        \n",
    "        txt=txt.lower()\n",
    "        \n",
    "        #removal of punctuations\n",
    "        \n",
    "        txt2=re.sub(r'[^a-z ]','',txt)\n",
    "        #months=['january','february','march','april','may','june','july','august','september','october','november','december']\n",
    "    \n",
    "        #removal of stopwords\n",
    "        chrlst=[wnl.lemmatize(u) for u in txt2.strip().split() if (u not in stop)]\n",
    "        \n",
    "        txt=s.join(chrlst)\n",
    "            \n",
    "        docs.append(txt)\n",
    "        labels.append(ct)\n",
    "        file.close()\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "all_data['Doc']=docs\n",
    "all_data['label']=labels\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=all_data.iloc[np.random.permutation(len(all_data))]\n",
    "all_data=all_data.reset_index(drop=True)\n",
    "x=all_data['Doc']\n",
    "y=all_data['label']\n",
    "count_vect = CountVectorizer()\n",
    "x_counts = count_vect.fit_transform(x)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_tfidf = tfidf_transformer.fit_transform(x_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training using various classifiers (k fold cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8028169 ,  0.73239437,  0.77142857,  0.81428571,  0.82857143,\n",
       "        0.85507246,  0.76119403,  0.81818182,  0.78787879,  0.78461538])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 fold cross validation \n",
    "clfMNB = MultinomialNB()\n",
    "scoresMNB = cross_val_score(clfMNB,x_tfidf , y, cv=10)\n",
    "print(scoresMNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85915493,  0.94366197,  0.9       ,  0.92857143,  0.97142857,\n",
       "        0.91304348,  0.8358209 ,  0.89393939,  0.89393939,  0.93846154])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 fold cross validation \n",
    "clfDT = DecisionTreeClassifier()\n",
    "scoresDT = cross_val_score(clfDT,x_tfidf , y, cv=10)\n",
    "scoresDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87323944,  0.91549296,  0.87142857,  0.92857143,  0.95714286,\n",
       "        0.94202899,  0.85074627,  0.87878788,  0.87878788,  0.87692308])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 fold cross validation \n",
    "clfRF = RandomForestClassifier()\n",
    "scoresRF = cross_val_score(clfRF,x_tfidf , y, cv=10)\n",
    "scoresRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71830986,  0.71830986,  0.58571429,  0.77142857,  0.75714286,\n",
       "        0.79710145,  0.76119403,  0.63636364,  0.77272727,  0.70769231])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 fold cross validation \n",
    "clfGNB = GaussianNB()\n",
    "scoresGNB = cross_val_score(clfGNB,x_tfidf.toarray() , y, cv=10)\n",
    "scoresGNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71830986,  0.69014085,  0.82857143,  0.82857143,  0.82857143,\n",
       "        0.7826087 ,  0.74626866,  0.6969697 ,  0.81818182,  0.75384615])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 fold cross validation \n",
    "clfK = KNeighborsClassifier()\n",
    "scoresK = cross_val_score(clfK,x_tfidf , y, cv=10)\n",
    "scoresK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
