{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManasviKundalia/Misc-NLP/blob/master/transformer_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d479e1",
      "metadata": {
        "id": "47d479e1"
      },
      "source": [
        "### Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "48fc6424",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48fc6424",
        "outputId": "69fa7c71-d470-47c8-f4d8-1c94b0ad36e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f4a653de",
      "metadata": {
        "id": "f4a653de"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9823edcb",
      "metadata": {
        "id": "9823edcb"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_check(response):\n",
        "  sentences = response.split(\".\")\n",
        "  result = []\n",
        "  for sentence in sentences:\n",
        "    if len(result)==0:\n",
        "      result.append(sentence)\n",
        "    else:\n",
        "      words = set(sentence.split())\n",
        "      prev_sentence_words = set(result[-1].split())\n",
        "      if words.intersection(prev_sentence_words) / max(len(prev_sentence_words), len(words)) > 0.5:\n",
        "        continue\n",
        "      result.append(sentence)\n",
        "    final_result = \". \".join(result)\n",
        "    words = final_result.split()\n",
        "    if len(set(words)) / len(words) < 0.3:\n",
        "      return \"I am not sure :(\"\n",
        "    return \". \".join(result)\n",
        "\n",
        "def generate_response(input_str):\n",
        "    input_ids = torch.tensor(tokenizer.encode(input_str)).unsqueeze(0)  # Encode the input string as a tensor\n",
        "    attention_mask = torch.ones_like(input_ids)  # Create an attention mask\n",
        "    pad_token_id = tokenizer.pad_token_id  # Get the pad token id\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id, max_length=100, top_p=0.95, top_k=0)  # Generate a response\n",
        "    return sanity_check(tokenizer.decode(output[0], skip_special_tokens=True))  # Decode the response and remove special tokens\n",
        "\n",
        "\n",
        "while True:\n",
        "    input_str = input(\"You: \")\n",
        "    if input_str == 'exit':\n",
        "        break\n",
        "    response = generate_response(input_str)\n",
        "    print(\"AI:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op2rPgQnivtF",
        "outputId": "6a9de71d-3efa-42ae-eca8-54b105b8f68f"
      },
      "id": "op2rPgQnivtF",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: What is a recommendation system?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: What is a recommendation system?\n",
            "\n",
            "A recommendation system is a system that allows you to make a recommendation based on your own experience\n",
            "You: What is physics?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: What is physics?\n",
            "\n",
            "Physicists have long known that the universe is a complex, fluid, and chaotic place\n",
            "You: Yes, but what is physics?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: Yes, but what is physics?\n",
            "\n",
            "The answer is that physics is a very complex system of laws and equations\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02cf4cd7",
      "metadata": {
        "id": "02cf4cd7"
      },
      "source": [
        "### Fine tune on WikiQA Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c91c8526",
      "metadata": {
        "id": "c91c8526"
      },
      "outputs": [],
      "source": [
        "POS_ANS_PATH = \"/content/WikiQASent.pos.ans.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1042189f",
      "metadata": {
        "id": "1042189f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_wikiqa = pd.read_csv(POS_ANS_PATH, delimiter=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "10d89352",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "10d89352",
        "outputId": "dcf5cc0c-42f7-4ab0-9125-bde9f3ec58c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  QuestionID                                         Question DocumentID  \\\n",
              "0         Q0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US         D0   \n",
              "1         Q1                    how are glacier caves formed?         D1   \n",
              "2         Q4                           how a water pump works         D4   \n",
              "3        Q11           how big is bmc software in houston, tx        D11   \n",
              "4        Q11           how big is bmc software in houston, tx        D11   \n",
              "\n",
              "                              DocumentTitle SentenceID  \\\n",
              "0  African immigration to the United States       D0-5   \n",
              "1                              Glacier cave       D1-3   \n",
              "2                                      Pump       D4-4   \n",
              "3                              BMC Software      D11-3   \n",
              "4                              BMC Software      D11-4   \n",
              "\n",
              "                                            Sentence AnswerPhrase1  \\\n",
              "0  As such, African immigrants are to be distingu...           NaN   \n",
              "1  A glacier cave is a cave formed within the ice...           NaN   \n",
              "2  Pumps operate by some mechanism (typically rec...           NaN   \n",
              "3  Employing over 6,000, BMC is often credited wi...           NaN   \n",
              "4  For 2011, the company recorded an annual reven...           NaN   \n",
              "\n",
              "                                       AnswerPhrase2  \\\n",
              "0  involuntarily brought to the United States by ...   \n",
              "1                        within the ice of a glacier   \n",
              "2  Pumps operate by some mechanism (typically rec...   \n",
              "3                               Employing over 6,000   \n",
              "4                     annual revenue of $2.1 billion   \n",
              "\n",
              "                                    AnswerPhrase3  \n",
              "0                            Atlantic slave trade  \n",
              "1              formed within the ice of a glacier  \n",
              "2  mechanism (typically reciprocating or rotary )  \n",
              "3                            Employing over 6,000  \n",
              "4                  annual revenue of $2.1 billion  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bba8210-eb53-4367-9a86-61624c75b95b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>Question</th>\n",
              "      <th>DocumentID</th>\n",
              "      <th>DocumentTitle</th>\n",
              "      <th>SentenceID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>AnswerPhrase1</th>\n",
              "      <th>AnswerPhrase2</th>\n",
              "      <th>AnswerPhrase3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-5</td>\n",
              "      <td>As such, African immigrants are to be distingu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>involuntarily brought to the United States by ...</td>\n",
              "      <td>Atlantic slave trade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-3</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>within the ice of a glacier</td>\n",
              "      <td>formed within the ice of a glacier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q4</td>\n",
              "      <td>how a water pump works</td>\n",
              "      <td>D4</td>\n",
              "      <td>Pump</td>\n",
              "      <td>D4-4</td>\n",
              "      <td>Pumps operate by some mechanism (typically rec...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pumps operate by some mechanism (typically rec...</td>\n",
              "      <td>mechanism (typically reciprocating or rotary )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q11</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>D11</td>\n",
              "      <td>BMC Software</td>\n",
              "      <td>D11-3</td>\n",
              "      <td>Employing over 6,000, BMC is often credited wi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Employing over 6,000</td>\n",
              "      <td>Employing over 6,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q11</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>D11</td>\n",
              "      <td>BMC Software</td>\n",
              "      <td>D11-4</td>\n",
              "      <td>For 2011, the company recorded an annual reven...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>annual revenue of $2.1 billion</td>\n",
              "      <td>annual revenue of $2.1 billion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bba8210-eb53-4367-9a86-61624c75b95b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bba8210-eb53-4367-9a86-61624c75b95b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bba8210-eb53-4367-9a86-61624c75b95b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df_wikiqa.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fea8e431",
      "metadata": {
        "id": "fea8e431"
      },
      "outputs": [],
      "source": [
        "conversations = [f\"{row['Question']} ? {row['Sentence']}\" for _, row in df_wikiqa.iterrows()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6c8e4565",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c8e4565",
        "outputId": "1ffdba18-be94-4b87-ec9c-74039ff4f0ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1473,\n",
              " ['HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US ? As such, African immigrants are to be distinguished from African American people, the latter of whom are descendants of mostly West and Central Africans who were involuntarily brought to the United States by means of the historic Atlantic slave trade .',\n",
              "  'how are glacier caves formed? ? A glacier cave is a cave formed within the ice of a glacier .',\n",
              "  'how a water pump works ? Pumps operate by some mechanism (typically reciprocating or rotary ), and consume energy to perform mechanical work by moving the fluid.',\n",
              "  'how big is bmc software in houston, tx ? Employing over 6,000, BMC is often credited with pioneering the BSM concept as a way to help better align IT operations with business needs.',\n",
              "  'how big is bmc software in houston, tx ? For 2011, the company recorded an annual revenue of $2.1 billion, making it the #20 largest software company in terms of revenue for that year.'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(conversations), conversations[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1c704b11",
      "metadata": {
        "id": "1c704b11"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WikiQADataset(Dataset):  \n",
        "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
        "\n",
        "        self.tokenizer = transformers.GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "        self.conversations = []\n",
        "\n",
        "        for row in conversations:\n",
        "            self.conversations.append(torch.tensor(\n",
        "                self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n",
        "            ))               \n",
        "        if truncate:\n",
        "            self.conversations = self.conversations[:20000]\n",
        "        self.convo_count = len(self.conversations)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.convo_count\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.conversations[item]\n",
        "    \n",
        "train_dataset = WikiQADataset(\"<BOS>\", truncate=True, gpt2_type=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ae7e8d2e",
      "metadata": {
        "id": "ae7e8d2e"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "#Accumulated batch size (since GPT2 is so big)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None\n",
        "\n",
        "def train(\n",
        "    dataset, model, tokenizer,\n",
        "    batch_size=32, epochs=5, lr=2e-4,\n",
        "    max_seq_len=400, warmup_steps=200,\n",
        "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
        "    test_mode=False,save_model_on_epoch=False,\n",
        "):\n",
        "    acc_steps = 10\n",
        "#     model = model.cuda()\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    loss=0\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        print(loss)\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "\n",
        "            if carry_on and idx != len(train_dataloader) - 1:\n",
        "                continue\n",
        "\n",
        "            outputs = model(input_tensor, labels=input_tensor)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "\n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "\n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "        if save_model_on_epoch:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
        "            )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "72606d05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72606d05",
        "outputId": "79891b2b-e8f7-4b3b-ed1b-dda19ddda2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1473it [18:58,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 1\n",
            "tensor(4.0089, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1473it [18:54,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 2\n",
            "tensor(3.3641, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1473it [18:58,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 3\n",
            "tensor(4.1742, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1473it [18:52,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 4\n",
            "tensor(3.4433, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1473it [18:54,  1.30it/s]\n"
          ]
        }
      ],
      "source": [
        "model = train(train_dataset, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa0fd81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aa0fd81",
        "outputId": "77965a70-b783-449e-a1e4-651017f31961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: What is a recommendation system?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: What is a recommendation system?\n",
            "\n",
            "A recommendation system is a system that allows you to make a decision about whether or not to make a recommendation\n",
            "You: How big is the sun?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: How big is the sun?\n",
            "\n",
            "The sun is the sun's diameter\n",
            "You: How did African Americans come to the US?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: How did African Americans come to the US?\n",
            "\n",
            "\n",
            "The first African American to come to the US was the first African American to be elected president of the United States\n",
            "You: When was slavery abolished?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: When was slavery abolished?\n",
            "\n",
            "The abolition of slavery was a major event in the history of the United States\n",
            "You: Can you tell me more about the French Revolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: Can you tell me more about the French Revolution?\n",
            "\n",
            "I think it was a very important event\n",
            "You: French Revolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: What is the story of Harry Potter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: What is the story of Harry Potter?\n",
            "\n",
            "Harry Potter is a character that has been in the works for over the years\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  input_str = input(\"You: \")\n",
        "  if input_str == 'exit':\n",
        "    break\n",
        "  response = generate_response(input_str)\n",
        "  print(\"AI:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc692ba",
      "metadata": {
        "id": "5fc692ba"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}