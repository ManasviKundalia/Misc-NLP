{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruchita\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (135,204,274,417,462) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Ruchita\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id             f1             f2             f3  \\\n",
      "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
      "mean    52736.000000     134.603171       8.246883       0.499066   \n",
      "std     30446.999458      14.725467       1.691535       0.288752   \n",
      "min         1.000000     103.000000       1.000000       0.000006   \n",
      "25%     26368.500000     124.000000       8.000000       0.248950   \n",
      "50%     52736.000000     129.000000       9.000000       0.498267   \n",
      "75%     79103.500000     148.000000       9.000000       0.749494   \n",
      "max    105471.000000     176.000000      11.000000       0.999994   \n",
      "\n",
      "                  f4             f5             f6             f7  \\\n",
      "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
      "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
      "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
      "min      1100.000000       1.000000       0.000000       1.000000   \n",
      "25%      1500.000000       4.000000   11255.000000            NaN   \n",
      "50%      2200.000000       4.000000   76530.000000            NaN   \n",
      "75%      3700.000000      10.000000   80135.000000            NaN   \n",
      "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
      "\n",
      "                  f8             f9      ...                 f770  \\\n",
      "count  105370.000000  105471.000000      ...        105471.000000   \n",
      "mean     2436.363718     134.555225      ...            17.422543   \n",
      "std      2262.950221      13.824682      ...            18.548936   \n",
      "min         1.000000     106.820000      ...             2.000000   \n",
      "25%              NaN     124.290000      ...             5.000000   \n",
      "50%              NaN     128.460000      ...            11.000000   \n",
      "75%              NaN     149.080000      ...            23.000000   \n",
      "max     11541.000000     172.950000      ...           168.000000   \n",
      "\n",
      "                f771           f772           f773           f774  \\\n",
      "count  105471.000000  105471.000000  105471.000000  104407.000000   \n",
      "mean        5.800976      -4.246788       3.273059       0.233852   \n",
      "std         6.508555       4.828265       3.766746       0.073578   \n",
      "min         0.000000     -43.160000       0.000000       0.000000   \n",
      "25%         1.480000      -5.700000       0.740000            NaN   \n",
      "50%         3.570000      -2.600000       1.990000            NaN   \n",
      "75%         7.700000      -1.010000       4.440000            NaN   \n",
      "max        58.120000       0.000000      34.040000       0.473700   \n",
      "\n",
      "                f775           f776           f777           f778  \\\n",
      "count  103946.000000  105471.000000  105471.000000  105471.000000   \n",
      "mean        0.014797       0.310246       0.322847     175.951589   \n",
      "std         1.039439       0.462597       0.467567     298.294043   \n",
      "min       -18.439600       0.000000       0.000000       2.000000   \n",
      "25%              NaN       0.000000       0.000000      19.000000   \n",
      "50%              NaN       0.000000       0.000000      40.000000   \n",
      "75%              NaN       1.000000       1.000000     104.000000   \n",
      "max        11.092000       1.000000       1.000000    1212.000000   \n",
      "\n",
      "                loss  \n",
      "count  105471.000000  \n",
      "mean        0.799585  \n",
      "std         4.321120  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max       100.000000  \n",
      "\n",
      "[8 rows x 751 columns]\n",
      "...\n",
      "Zero-loss instances :  95688\n",
      "\n",
      "Non-zero loss instances :  9783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load train data\n",
    "train_data=[pd.read_csv('C:/Users/Ruchita/Desktop/loan dataset- ephesoft/train_v2.csv')]\n",
    "\n",
    "print(train_data[0].describe())\n",
    "\n",
    "target=[int(train_data[0]['loss'][i]!=0) for i in range(len(train_data[0]))]\n",
    "train_data[0]['target']=target\n",
    "\n",
    "#number of instances of each class\n",
    "print('...')\n",
    "print('Zero-loss instances : ',target.count(0))\n",
    "print()\n",
    "print('Non-zero loss instances : ',target.count(1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..ALL COLUMNS..  772\n",
      "\n",
      "..COLUMNS WITH MISSING VALUES..  525\n",
      "\n",
      "..UNIQUE DATATYPES.. 4\n",
      "[<class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'numpy.float64'>]\n",
      "\n",
      "..Numerical columns..  757\n",
      "\n",
      "..String datatype columns..  15\n",
      "\n",
      "..string continuous..  15\n",
      "..string categorical.. 0\n",
      "                      f138                f207                   f277  \\\n",
      "0    754485076006959972352   38600000000000000  683091368180479950848   \n",
      "1        15300000000000000    1690000000000000    2140000000000000000   \n",
      "2      6910365323840000000  389000000000000000      69200000000000000   \n",
      "3  11225194901267999096832      35000000000000     295000000000000000   \n",
      "4          108000000000000    1870000000000000      23100000000000000   \n",
      "\n",
      "            f338                            f390  \\\n",
      "0  7610000000000   10370164393071999997033054208   \n",
      "1      796594176    5098137566366599989877014528   \n",
      "2   461000000000   26400269714792999161039945728   \n",
      "3  1330000000000    9333818143939599917454983168   \n",
      "4  2240000000000  196004669899870011305513451520   \n",
      "\n",
      "                                      f391             f420  \\\n",
      "0   13621142007705000132589703585884798976  511000000000000   \n",
      "1    5366154527659000357778647583412977664       1593188352   \n",
      "2   36117033568522998807722429270944907264   63500000000000   \n",
      "3   12638526060843999893906772076814925824    9380000000000   \n",
      "4  428213273484070002013091334592080642048  659000000000000   \n",
      "\n",
      "                        f469                              f472  \\\n",
      "0   569877634360569973702656   3427303293502300223465356001280   \n",
      "1         107000000000000000            9894337169928600158208   \n",
      "2      313319151143610023936       222812827058929985669562368   \n",
      "3  2641626213765599994052608  24452856014536001129152839155712   \n",
      "4             68300000000000                922000000000000000   \n",
      "\n",
      "                       f534                             f537  \\\n",
      "0  240811094251680005357568  1185103615651699994464937312256   \n",
      "1     251470350285930004480      161196782629860003268263936   \n",
      "2     116067852739909992448       61668865475731997253959680   \n",
      "3     202899352692079984640      126293716597939998795235328   \n",
      "4        654000000000000000          89341826582645997305856   \n",
      "\n",
      "                             f626                                     f627  \\\n",
      "0   11724173453590999285553430528   16027029142402000396838501389877379072   \n",
      "1    6391495663130699779035627520    7158933769610900052770065343332745216   \n",
      "2   36420952401170000260810932224   56027915541865997900093655676589441024   \n",
      "3   15267506423634001098621059072   24362045267421999852972382580757233664   \n",
      "4  238204359524660008028924280832  550170020491249969340152709153269219328   \n",
      "\n",
      "                    f695                  f698  \n",
      "0    8700000000000000000   8010000000000000000  \n",
      "1    5890000000000000000   5030000000000000000  \n",
      "2   24512111987574001664  19855991371293999104  \n",
      "3    9660000000000000000   6960000000000000000  \n",
      "4  108505460071560003584  94766610066210996224  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruchita\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id             f1             f2             f3  \\\n",
      "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
      "mean    52736.000000     134.603171       8.246883       0.499066   \n",
      "std     30446.999458      14.725467       1.691535       0.288752   \n",
      "min         1.000000     103.000000       1.000000       0.000006   \n",
      "25%     26368.500000     124.000000       8.000000       0.248950   \n",
      "50%     52736.000000     129.000000       9.000000       0.498267   \n",
      "75%     79103.500000     148.000000       9.000000       0.749494   \n",
      "max    105471.000000     176.000000      11.000000       0.999994   \n",
      "\n",
      "                  f4             f5             f6             f7  \\\n",
      "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
      "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
      "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
      "min      1100.000000       1.000000       0.000000       1.000000   \n",
      "25%      1500.000000       4.000000   11255.000000            NaN   \n",
      "50%      2200.000000       4.000000   76530.000000            NaN   \n",
      "75%      3700.000000      10.000000   80135.000000            NaN   \n",
      "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
      "\n",
      "                  f8             f9      ...                 f771  \\\n",
      "count  105370.000000  105471.000000      ...        105471.000000   \n",
      "mean     2436.363718     134.555225      ...             5.800976   \n",
      "std      2262.950221      13.824682      ...             6.508555   \n",
      "min         1.000000     106.820000      ...             0.000000   \n",
      "25%              NaN     124.290000      ...             1.480000   \n",
      "50%              NaN     128.460000      ...             3.570000   \n",
      "75%              NaN     149.080000      ...             7.700000   \n",
      "max     11541.000000     172.950000      ...            58.120000   \n",
      "\n",
      "                f772           f773           f774           f775  \\\n",
      "count  105471.000000  105471.000000  104407.000000  103946.000000   \n",
      "mean       -4.246788       3.273059       0.233852       0.014797   \n",
      "std         4.828265       3.766746       0.073578       1.039439   \n",
      "min       -43.160000       0.000000       0.000000     -18.439600   \n",
      "25%        -5.700000       0.740000            NaN            NaN   \n",
      "50%        -2.600000       1.990000            NaN            NaN   \n",
      "75%        -1.010000       4.440000            NaN            NaN   \n",
      "max         0.000000      34.040000       0.473700      11.092000   \n",
      "\n",
      "                f776           f777           f778           loss  \\\n",
      "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
      "mean        0.310246       0.322847     175.951589       0.799585   \n",
      "std         0.462597       0.467567     298.294043       4.321120   \n",
      "min         0.000000       0.000000       2.000000       0.000000   \n",
      "25%         0.000000       0.000000      19.000000       0.000000   \n",
      "50%         0.000000       0.000000      40.000000       0.000000   \n",
      "75%         1.000000       1.000000     104.000000       0.000000   \n",
      "max         1.000000       1.000000    1212.000000     100.000000   \n",
      "\n",
      "              target  \n",
      "count  105471.000000  \n",
      "mean        0.092755  \n",
      "std         0.290091  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 752 columns]\n"
     ]
    }
   ],
   "source": [
    "# There are significant missing values in the data as well as class imbalance\n",
    "# Also certain columns have mixed datatypes.. These have to be converted to integer values\n",
    "\n",
    "#function to map all values to int\n",
    "def map_int(x):\n",
    "    try:\n",
    "        y=int(x)\n",
    "    except:\n",
    "        y=x #in case of nan\n",
    "    return y\n",
    "\n",
    "columns = list(train_data[0].columns)\n",
    "print('..ALL COLUMNS.. ',len(columns))\n",
    "print()\n",
    "\n",
    "# columns 135,204,274,417,462 have mixed datatypes i.e. numeric entries but int/str datatypes\n",
    "# since these columns contain numeric entries we will map these to int datatype\n",
    "mixed_datatypes=[135,204,274,417,462]\n",
    "mixed_cols_names=[columns[i] for i in mixed_datatypes]\n",
    "for col_name in mixed_cols_names:\n",
    "    train_data[0][col_name]=train_data[0][col_name].map(lambda x:map_int(x))\n",
    "\n",
    "#1. number of columns with missing values\n",
    "missing_cols = [column for column in columns if train_data[0][column].count()!=len(train_data[0])]\n",
    "print('..COLUMNS WITH MISSING VALUES.. ',len(missing_cols))\n",
    "print()\n",
    "\n",
    "# all datatypes\n",
    "datatypes = list(set([type(train_data[0][column][0]) for column in columns]))\n",
    "print('..UNIQUE DATATYPES..', len(datatypes))\n",
    "print(datatypes)\n",
    "print()\n",
    "\n",
    "#2. types of features- continuous or categorical, numeric or string\n",
    "numeric = [column for column in columns if type(train_data[0][column][0])!=str]\n",
    "print('..Numerical columns.. ',len(numeric))\n",
    "print()\n",
    "string = [column for column in columns if type(train_data[0][column][0])==str]\n",
    "print('..String datatype columns.. ',len(string))\n",
    "print()\n",
    "## string categorical or continuous\n",
    "string_continuous=[column for column in string if len(train_data[0][column].unique())>50]\n",
    "string_categorical=list(set(string).difference(set(string_continuous)))\n",
    "print('..string continuous.. ', len(string_continuous))\n",
    "print('..string categorical..', len(string_categorical))\n",
    "\n",
    "print(train_data[0][string].head())\n",
    "\n",
    "#all string datatype columns can be mapped to their integer values\n",
    "\n",
    "for col_name in string:\n",
    "    train_data[0][col_name]=train_data[0][col_name].map(lambda x:map_int(x))\n",
    "\n",
    "#thus all columns now comprise of integers/floats with some missing values\n",
    "\n",
    "print(train_data[0].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dealing with missing values using mean substitution\n",
    "\n",
    "for col in missing_cols:\n",
    "    train_data[0].loc[train_data[0][col].isnull()==True,col]=train_data[0][col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Class imbalance can be tackled using Oversampling Techniques\n",
    "\n",
    "#step 1: divide the data into 10 smaller datasets maintaining the class imbalance\n",
    "\n",
    "train_data[0]=train_data[0].iloc[np.random.permutation(range(len(train_data[0])))]\n",
    "train_data[0]=train_data[0].reset_index(drop=True)\n",
    "\n",
    "majority=[train_data[0][train_data[0]['target']==0]]\n",
    "minority=[train_data[0][train_data[0]['target']==1]]\n",
    "\n",
    "del train_data\n",
    "\n",
    "k_maj=int(len(majority[0])/10)  #part size\n",
    "k_min=int(len(minority[0])/10)  #part size\n",
    "\n",
    "train_data_10=[pd.concat([majority[0][i*k_maj:(i+1)*k_maj],minority[0][i*k_min:(i+1)*k_min]]) for i in range(10)]\n",
    "train_data_10.append(pd.concat([majority[0][9*k_maj:],minority[0][9*k_min:]]))\n",
    "\n",
    "del majority\n",
    "del minority\n",
    "\n",
    "def shuffle_and_resetindex(df):\n",
    "    df=df.iloc[np.random.permutation(range(len(df)))]\n",
    "    df=df.iloc[np.random.permutation(range(len(df)))]\n",
    "    df=df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_10=[shuffle_and_resetindex(x) for x in train_data_10]\n",
    "train_data = train_data_10[:6]\n",
    "test_data  = train_data_10[6:]\n",
    "del train_data_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instead of oversampling the entire data we will resample a fraction of the data (6/11) and test the models on the original unsampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote\n",
      "smoteb1\n",
      "smoteb2\n",
      "random\n",
      "adasyn\n",
      "smote\n"
     ]
    }
   ],
   "source": [
    "#oversampling \n",
    "\n",
    "def oversample(X,Y,sampler):\n",
    "    s=['smote','smoteb1','smoteb2','smotesvm','random','adasyn']\n",
    "    print(sampler)\n",
    "    if sampler==s[0]:\n",
    "        sm=SMOTE(kind='regular')\n",
    "    elif sampler==s[1]:\n",
    "        sm=SMOTE(kind='borderline1')\n",
    "    elif sampler==s[2]:\n",
    "        sm=SMOTE(kind='borderline2')\n",
    "    elif sampler==s[3]:\n",
    "        sm=SMOTE(kind='svm')\n",
    "    elif sampler==s[4]:\n",
    "        sm=RandomOverSampler()\n",
    "    else:\n",
    "        sm=ADASYN()\n",
    "    X_resampled,Y_resampled = sm.fit_sample(X,Y)\n",
    "    return X_resampled,Y_resampled\n",
    "\n",
    "features=list(train_data[0].columns)\n",
    "features.remove('loss')\n",
    "features.remove('target')\n",
    "'''\n",
    ".......\n",
    ".......\n",
    "CHANGE CODE HERE TO CHOOSE SAMPLING TECHNIQUE\n",
    "\n",
    "samplers=['smote','smoteb1','smoteb2','random','adasyn','smote','smoteb1','smoteb2','random','adasyn','smotesvm']\n",
    "xy_resampled=[oversample(train_data[i][features],train_data[i]['target'],samplers[i]) for i in range(len(train_data))]\n",
    "\n",
    ".......\n",
    ".......\n",
    "'''\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "def feature_select(x,y,k):\n",
    "    kb = SelectKBest(f_classif,k)\n",
    "    kb.fit(x,y)\n",
    "    x_new= kb.fit_transform(x,y)\n",
    "    params=kb.get_params()\n",
    "    scores=kb.scores_\n",
    "    return x_new,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruchita\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [ 31  32  33  35  36 669 691 692 693 727 755] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#kbest_xy=[(feature_select(a,b,100),b) for (a,b) in xy_resampled]\n",
    "import operator\n",
    "(a,b)=xy_resampled[0]\n",
    "x_new,scores=feature_select(a,b,100)\n",
    "dct=dict([[i,scores[i]] for i in range(len(scores))])\n",
    "sorted_dct = sorted(dct.items(), key=operator.itemgetter(1))\n",
    "c=sorted_dct[-100:]\n",
    "top_features=[features[c[i][0]] for i in range(len(c))]\n",
    "print(type(top_features))\n",
    "(jx,jy)=xy_resampled[1]\n",
    "jx=pd.DataFrame(jx,columns=features).head()\n",
    "xx=jx[top_features]\n",
    "kbest_train=[(pd.DataFrame(a,columns=features)[top_features],b) for (a,b) in xy_resampled]\n",
    "kbest_test =[(a[top_features],a['target']) for a in test_data]\n",
    "del test_data\n",
    "del xy_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del xy_resampled\n",
    "clfs=[RandomForestClassifier(n_estimators=50),DecisionTreeClassifier(),AdaBoostClassifier(),KNeighborsClassifier(),RandomForestClassifier(n_estimators=50),LogisticRegression()]\n",
    "clf_names=['RANDOM FOREST','DECISION TREE','ADA BOOST','KNN','RANDOM FOREST','Logistic Regression']\n",
    "\n",
    "def train(kbest_train,clfs,clf_names):\n",
    "    for i in range(len(kbest_train)):\n",
    "        (x,y)=kbest_train[i]\n",
    "        clfs[i].fit(x,y)\n",
    "    return clfs\n",
    "\n",
    "trained_cls=train(kbest_train,clfs,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(kbest_test,trained_cls,clf_names):\n",
    "    for i in range(len(trained_cls)):\n",
    "        print('.....')\n",
    "        print(clf_names[i])\n",
    "        scores=[]\n",
    "        f_scores=[]\n",
    "        for j in range(len(kbest_test)):\n",
    "            (x,y)=kbest_test[j]\n",
    "            prec,recall,f_score,d=precision_recall_fscore_support(y,trained_cls[i].predict(x),pos_label=1,average='binary')\n",
    "            print('Dataset : ',j)\n",
    "            print('Precision : ',prec,' ,Recall : ',recall,'F_score : ',f_score)\n",
    "            print()     \n",
    "            f_scores.append(f_score)\n",
    "            scores.append(trained_cls[i].score(x,y))\n",
    "        print('Avg. performance : ',sum(scores)/len(scores))\n",
    "        print('Avg. f_score : ',sum(f_scores)/len(f_scores))\n",
    "        print()\n",
    "        print('.....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      "RANDOM FOREST\n",
      "Dataset :  0\n",
      "Precision :  0.181818181818  ,Recall :  0.0122699386503 F_score :  0.0229885057471\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.132075471698  ,Recall :  0.00715746421268 F_score :  0.0135790494665\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.0961538461538  ,Recall :  0.00511247443763 F_score :  0.00970873786408\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.0877192982456  ,Recall :  0.00511247443763 F_score :  0.00966183574879\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.0877192982456  ,Recall :  0.00509683995923 F_score :  0.00963391136802\n",
      "\n",
      "Avg. performance :  0.903111533048\n",
      "Avg. f_score :  0.0131144080389\n",
      "\n",
      ".....\n",
      ".....\n",
      "DECISION TREE\n",
      "Dataset :  0\n",
      "Precision :  0.113584036838  ,Recall :  0.151329243354 F_score :  0.129767645769\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.112915699923  ,Recall :  0.149284253579 F_score :  0.128577719066\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.102290076336  ,Recall :  0.137014314928 F_score :  0.117132867133\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.112547528517  ,Recall :  0.151329243354 F_score :  0.12908853031\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.112462006079  ,Recall :  0.150866462793 F_score :  0.128863735307\n",
      "\n",
      "Avg. performance :  0.810735538921\n",
      "Avg. f_score :  0.126686099517\n",
      "\n",
      ".....\n",
      ".....\n",
      "ADA BOOST\n",
      "Dataset :  0\n",
      "Precision :  0.136120042872  ,Recall :  0.129856850716 F_score :  0.132914704343\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.132516703786  ,Recall :  0.121676891616 F_score :  0.126865671642\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.125  ,Recall :  0.120654396728 F_score :  0.122788761707\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.137339055794  ,Recall :  0.130879345603 F_score :  0.134031413613\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.137339055794  ,Recall :  0.130479102956 F_score :  0.13382122321\n",
      "\n",
      "Avg. performance :  0.842778807741\n",
      "Avg. f_score :  0.130084354903\n",
      "\n",
      ".....\n",
      ".....\n",
      "KNN\n",
      "Dataset :  0\n",
      "Precision :  0.111407859596  ,Recall :  0.298568507157 F_score :  0.162267296471\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.12003087611  ,Recall :  0.31799591002 F_score :  0.174278509386\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.103651354535  ,Recall :  0.269938650307 F_score :  0.149787234043\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.112178255859  ,Recall :  0.298568507157 F_score :  0.163082937727\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.113156885309  ,Recall :  0.300713557594 F_score :  0.164437012263\n",
      "\n",
      "Avg. performance :  0.716463565411\n",
      "Avg. f_score :  0.162770597978\n",
      "\n",
      ".....\n",
      ".....\n",
      "RANDOM FOREST\n",
      "Dataset :  0\n",
      "Precision :  0.0  ,Recall :  0.0 F_score :  0.0\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.0  ,Recall :  0.0 F_score :  0.0\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.0  ,Recall :  0.0 F_score :  0.0\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.375  ,Recall :  0.00306748466258 F_score :  0.00608519269777\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.375  ,Recall :  0.00305810397554 F_score :  0.00606673407482\n",
      "\n",
      "Avg. performance :  0.906410473152\n",
      "Avg. f_score :  0.00243038535452\n",
      "\n",
      ".....\n",
      ".....\n",
      "Logistic Regression\n",
      "Dataset :  0\n",
      "Precision :  0.150325162581  ,Recall :  0.614519427403 F_score :  0.241559485531\n",
      "\n",
      "Dataset :  1\n",
      "Precision :  0.150933997509  ,Recall :  0.61963190184 F_score :  0.24273983577\n",
      "\n",
      "Dataset :  2\n",
      "Precision :  0.149683944374  ,Recall :  0.605316973415 F_score :  0.240016217312\n",
      "\n",
      "Dataset :  3\n",
      "Precision :  0.15119836818  ,Recall :  0.606339468303 F_score :  0.242040816327\n",
      "\n",
      "Dataset :  4\n",
      "Precision :  0.151847133758  ,Recall :  0.60754332314 F_score :  0.242967794537\n",
      "\n",
      "Avg. performance :  0.644829695608\n",
      "Avg. f_score :  0.241864829895\n",
      "\n",
      ".....\n"
     ]
    }
   ],
   "source": [
    "test(kbest_test,trained_cls,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
